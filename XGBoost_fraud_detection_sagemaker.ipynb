{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an Supervised XGBoost model using the data stored in feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries and initialising the boto session and the feature store session \n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the feature group created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the sagemaker feature group module to ingest data from feature store\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "fd_feature_group_name = 'transactionfeaturegroup'\n",
    "\n",
    "fd_feature_group = FeatureGroup(name=fd_feature_group_name, sagemaker_session=feature_store_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Dataset using feature group\n",
    "\n",
    "We will be using both identity and transaction feature groups.\n",
    "Running athena job to join the data stored in S3 from 2 from feature group\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-ap-south-1-080451317723\n"
     ]
    }
   ],
   "source": [
    "# initialising a default bucket\n",
    "default_s3_bucket_name = feature_store_session.default_bucket()\n",
    "prefix = 'sagemaker-featurestore'\n",
    "\n",
    "print(default_s3_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactionfeaturegroup-1639487824\n",
      "Running SELECT * FROM \"transactionfeaturegroup-1639487824\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "      <th>event_time</th>\n",
       "      <th>record_id</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154562.0</td>\n",
       "      <td>1.434671</td>\n",
       "      <td>-1.291996</td>\n",
       "      <td>-1.132534</td>\n",
       "      <td>0.431622</td>\n",
       "      <td>-0.435673</td>\n",
       "      <td>0.656909</td>\n",
       "      <td>-0.652167</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>1.161493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345469</td>\n",
       "      <td>-0.055816</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>295.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>249755</td>\n",
       "      <td>2021-12-14 13:28:50.251</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156172.0</td>\n",
       "      <td>1.853259</td>\n",
       "      <td>-0.140104</td>\n",
       "      <td>-2.066584</td>\n",
       "      <td>1.151793</td>\n",
       "      <td>0.530221</td>\n",
       "      <td>-0.920152</td>\n",
       "      <td>0.693785</td>\n",
       "      <td>-0.254771</td>\n",
       "      <td>-0.094436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481879</td>\n",
       "      <td>-0.064670</td>\n",
       "      <td>-0.064917</td>\n",
       "      <td>101.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>253273</td>\n",
       "      <td>2021-12-14 13:28:50.251</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95534.0</td>\n",
       "      <td>1.998042</td>\n",
       "      <td>-0.150028</td>\n",
       "      <td>-0.564531</td>\n",
       "      <td>1.057674</td>\n",
       "      <td>-0.212438</td>\n",
       "      <td>-0.375196</td>\n",
       "      <td>-0.242937</td>\n",
       "      <td>-0.171510</td>\n",
       "      <td>2.468904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>-0.059418</td>\n",
       "      <td>-0.054060</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>151437</td>\n",
       "      <td>2021-12-14 13:28:50.251</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139023.0</td>\n",
       "      <td>1.709209</td>\n",
       "      <td>0.921867</td>\n",
       "      <td>-2.349246</td>\n",
       "      <td>4.263352</td>\n",
       "      <td>1.164863</td>\n",
       "      <td>-0.712155</td>\n",
       "      <td>0.730886</td>\n",
       "      <td>-0.102934</td>\n",
       "      <td>-1.354044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>-0.049081</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>91.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>212867</td>\n",
       "      <td>2021-12-14 13:28:50.251</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10369.0</td>\n",
       "      <td>1.111065</td>\n",
       "      <td>0.545980</td>\n",
       "      <td>0.750707</td>\n",
       "      <td>2.450146</td>\n",
       "      <td>0.191360</td>\n",
       "      <td>0.481849</td>\n",
       "      <td>-0.197253</td>\n",
       "      <td>0.166455</td>\n",
       "      <td>0.417873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270529</td>\n",
       "      <td>-0.027408</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>10.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>7551</td>\n",
       "      <td>2021-12-14 13:28:50.251</td>\n",
       "      <td>2021-12-14 13:22:52.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>157776.0</td>\n",
       "      <td>-0.483629</td>\n",
       "      <td>0.862919</td>\n",
       "      <td>0.241969</td>\n",
       "      <td>-0.785442</td>\n",
       "      <td>0.427982</td>\n",
       "      <td>-0.787577</td>\n",
       "      <td>1.068080</td>\n",
       "      <td>-0.206279</td>\n",
       "      <td>0.351421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109604</td>\n",
       "      <td>0.318189</td>\n",
       "      <td>-0.022686</td>\n",
       "      <td>21.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>256612</td>\n",
       "      <td>2021-12-14 13:23:02.559</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>106391.0</td>\n",
       "      <td>-0.605921</td>\n",
       "      <td>0.938154</td>\n",
       "      <td>2.359743</td>\n",
       "      <td>-0.142475</td>\n",
       "      <td>0.115729</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.588859</td>\n",
       "      <td>-0.320029</td>\n",
       "      <td>1.516950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.738756</td>\n",
       "      <td>-0.199762</td>\n",
       "      <td>-0.152970</td>\n",
       "      <td>11.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>155792</td>\n",
       "      <td>2021-12-14 13:23:02.559</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>84210.0</td>\n",
       "      <td>-0.492857</td>\n",
       "      <td>0.923590</td>\n",
       "      <td>1.649824</td>\n",
       "      <td>-0.085427</td>\n",
       "      <td>-0.173034</td>\n",
       "      <td>-0.702497</td>\n",
       "      <td>0.580665</td>\n",
       "      <td>0.100432</td>\n",
       "      <td>-0.580246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042887</td>\n",
       "      <td>0.254814</td>\n",
       "      <td>0.112425</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>141272</td>\n",
       "      <td>2021-12-14 13:23:02.559</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>134419.0</td>\n",
       "      <td>0.060522</td>\n",
       "      <td>0.787730</td>\n",
       "      <td>-0.146108</td>\n",
       "      <td>-0.964349</td>\n",
       "      <td>1.035412</td>\n",
       "      <td>-0.071046</td>\n",
       "      <td>0.920963</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>-0.286318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192135</td>\n",
       "      <td>0.245111</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>202623</td>\n",
       "      <td>2021-12-14 13:23:02.559</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>56120.0</td>\n",
       "      <td>1.213275</td>\n",
       "      <td>0.281295</td>\n",
       "      <td>-0.906581</td>\n",
       "      <td>1.322545</td>\n",
       "      <td>2.311149</td>\n",
       "      <td>3.727476</td>\n",
       "      <td>-0.434505</td>\n",
       "      <td>0.878300</td>\n",
       "      <td>-0.864782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060465</td>\n",
       "      <td>-0.009346</td>\n",
       "      <td>0.020662</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>75554</td>\n",
       "      <td>2021-12-14 13:23:02.559</td>\n",
       "      <td>2021-12-14 13:22:51.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time        v1        v2        v3        v4        v5        v6  \\\n",
       "0      154562.0  1.434671 -1.291996 -1.132534  0.431622 -0.435673  0.656909   \n",
       "1      156172.0  1.853259 -0.140104 -2.066584  1.151793  0.530221 -0.920152   \n",
       "2       95534.0  1.998042 -0.150028 -0.564531  1.057674 -0.212438 -0.375196   \n",
       "3      139023.0  1.709209  0.921867 -2.349246  4.263352  1.164863 -0.712155   \n",
       "4       10369.0  1.111065  0.545980  0.750707  2.450146  0.191360  0.481849   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99995  157776.0 -0.483629  0.862919  0.241969 -0.785442  0.427982 -0.787577   \n",
       "99996  106391.0 -0.605921  0.938154  2.359743 -0.142475  0.115729 -0.222119   \n",
       "99997   84210.0 -0.492857  0.923590  1.649824 -0.085427 -0.173034 -0.702497   \n",
       "99998  134419.0  0.060522  0.787730 -0.146108 -0.964349  1.035412 -0.071046   \n",
       "99999   56120.0  1.213275  0.281295 -0.906581  1.322545  2.311149  3.727476   \n",
       "\n",
       "             v7        v8        v9  ...       v26       v27       v28  \\\n",
       "0     -0.652167  0.276189  1.161493  ...  0.345469 -0.055816  0.026946   \n",
       "1      0.693785 -0.254771 -0.094436  ... -0.481879 -0.064670 -0.064917   \n",
       "2     -0.242937 -0.171510  2.468904  ...  0.001702 -0.059418 -0.054060   \n",
       "3      0.730886 -0.102934 -1.354044  ... -0.002726 -0.049081  0.011048   \n",
       "4     -0.197253  0.166455  0.417873  ... -0.270529 -0.027408  0.005097   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "99995  1.068080 -0.206279  0.351421  ...  0.109604  0.318189 -0.022686   \n",
       "99996  0.588859 -0.320029  1.516950  ... -0.738756 -0.199762 -0.152970   \n",
       "99997  0.580665  0.100432 -0.580246  ...  0.042887  0.254814  0.112425   \n",
       "99998  0.920963  0.013015 -0.286318  ...  0.192135  0.245111  0.076804   \n",
       "99999 -0.434505  0.878300 -0.864782  ... -0.060465 -0.009346  0.020662   \n",
       "\n",
       "       amount  class    event_time  record_id               write_time  \\\n",
       "0      295.30      0  1.639488e+09     249755  2021-12-14 13:28:50.251   \n",
       "1      101.50      0  1.639488e+09     253273  2021-12-14 13:28:50.251   \n",
       "2        0.01      0  1.639488e+09     151437  2021-12-14 13:28:50.251   \n",
       "3       91.01      0  1.639488e+09     212867  2021-12-14 13:28:50.251   \n",
       "4       10.25      0  1.639488e+09       7551  2021-12-14 13:28:50.251   \n",
       "...       ...    ...           ...        ...                      ...   \n",
       "99995   21.99      0  1.639488e+09     256612  2021-12-14 13:23:02.559   \n",
       "99996   11.27      0  1.639488e+09     155792  2021-12-14 13:23:02.559   \n",
       "99997    9.99      0  1.639488e+09     141272  2021-12-14 13:23:02.559   \n",
       "99998    9.99      0  1.639488e+09     202623  2021-12-14 13:23:02.559   \n",
       "99999   20.00      0  1.639488e+09      75554  2021-12-14 13:23:02.559   \n",
       "\n",
       "           api_invocation_time  is_deleted  \n",
       "0      2021-12-14 13:22:51.000       False  \n",
       "1      2021-12-14 13:22:51.000       False  \n",
       "2      2021-12-14 13:22:51.000       False  \n",
       "3      2021-12-14 13:22:51.000       False  \n",
       "4      2021-12-14 13:22:52.000       False  \n",
       "...                        ...         ...  \n",
       "99995  2021-12-14 13:22:51.000       False  \n",
       "99996  2021-12-14 13:22:51.000       False  \n",
       "99997  2021-12-14 13:22:51.000       False  \n",
       "99998  2021-12-14 13:22:51.000       False  \n",
       "99999  2021-12-14 13:22:51.000       False  \n",
       "\n",
       "[100000 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running athena query on the feature store stored in S3 bucket\n",
    "transaction_query = fd_feature_group.athena_query()\n",
    "\n",
    "#storeing the table name variable\n",
    "transaction_table = transaction_query.table_name\n",
    "\n",
    "print(transaction_table)\n",
    "\n",
    "\n",
    "# query to be run \n",
    "query_string = 'SELECT * FROM \"'+transaction_table+'\"'\n",
    "print('Running ' + query_string)\n",
    "\n",
    "# running the query and storing the pandas dataframe created to S3 bucket in query results sub folder\n",
    "transaction_query.run(query_string=query_string, output_location='s3://'+default_s3_bucket_name+'/'+prefix+'/query_results/')\n",
    "transaction_query.wait()\n",
    "dataset = transaction_query.as_dataframe()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the columns to be used from the data frame\n",
    "dataset = dataset[['time', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10',\n",
    "       'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20',\n",
    "       'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'amount',\n",
    "       'class']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154562.0</td>\n",
       "      <td>1.434671</td>\n",
       "      <td>-1.291996</td>\n",
       "      <td>-1.132534</td>\n",
       "      <td>0.431622</td>\n",
       "      <td>-0.435673</td>\n",
       "      <td>0.656909</td>\n",
       "      <td>-0.652167</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>1.161493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135988</td>\n",
       "      <td>-0.182828</td>\n",
       "      <td>-0.037648</td>\n",
       "      <td>-0.229441</td>\n",
       "      <td>-0.588768</td>\n",
       "      <td>0.345469</td>\n",
       "      <td>-0.055816</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>295.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156172.0</td>\n",
       "      <td>1.853259</td>\n",
       "      <td>-0.140104</td>\n",
       "      <td>-2.066584</td>\n",
       "      <td>1.151793</td>\n",
       "      <td>0.530221</td>\n",
       "      <td>-0.920152</td>\n",
       "      <td>0.693785</td>\n",
       "      <td>-0.254771</td>\n",
       "      <td>-0.094436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192666</td>\n",
       "      <td>0.326074</td>\n",
       "      <td>-0.120927</td>\n",
       "      <td>-0.446195</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>-0.481879</td>\n",
       "      <td>-0.064670</td>\n",
       "      <td>-0.064917</td>\n",
       "      <td>101.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95534.0</td>\n",
       "      <td>1.998042</td>\n",
       "      <td>-0.150028</td>\n",
       "      <td>-0.564531</td>\n",
       "      <td>1.057674</td>\n",
       "      <td>-0.212438</td>\n",
       "      <td>-0.375196</td>\n",
       "      <td>-0.242937</td>\n",
       "      <td>-0.171510</td>\n",
       "      <td>2.468904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508941</td>\n",
       "      <td>-0.841443</td>\n",
       "      <td>0.373076</td>\n",
       "      <td>1.107912</td>\n",
       "      <td>-0.183633</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>-0.059418</td>\n",
       "      <td>-0.054060</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139023.0</td>\n",
       "      <td>1.709209</td>\n",
       "      <td>0.921867</td>\n",
       "      <td>-2.349246</td>\n",
       "      <td>4.263352</td>\n",
       "      <td>1.164863</td>\n",
       "      <td>-0.712155</td>\n",
       "      <td>0.730886</td>\n",
       "      <td>-0.102934</td>\n",
       "      <td>-1.354044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092148</td>\n",
       "      <td>-0.422369</td>\n",
       "      <td>-0.008842</td>\n",
       "      <td>-0.300789</td>\n",
       "      <td>0.093130</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>-0.049081</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>91.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10369.0</td>\n",
       "      <td>1.111065</td>\n",
       "      <td>0.545980</td>\n",
       "      <td>0.750707</td>\n",
       "      <td>2.450146</td>\n",
       "      <td>0.191360</td>\n",
       "      <td>0.481849</td>\n",
       "      <td>-0.197253</td>\n",
       "      <td>0.166455</td>\n",
       "      <td>0.417873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346103</td>\n",
       "      <td>-0.880483</td>\n",
       "      <td>0.136438</td>\n",
       "      <td>-0.435264</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>-0.270529</td>\n",
       "      <td>-0.027408</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>10.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time        v1        v2        v3        v4        v5        v6  \\\n",
       "0  154562.0  1.434671 -1.291996 -1.132534  0.431622 -0.435673  0.656909   \n",
       "1  156172.0  1.853259 -0.140104 -2.066584  1.151793  0.530221 -0.920152   \n",
       "2   95534.0  1.998042 -0.150028 -0.564531  1.057674 -0.212438 -0.375196   \n",
       "3  139023.0  1.709209  0.921867 -2.349246  4.263352  1.164863 -0.712155   \n",
       "4   10369.0  1.111065  0.545980  0.750707  2.450146  0.191360  0.481849   \n",
       "\n",
       "         v7        v8        v9  ...       v21       v22       v23       v24  \\\n",
       "0 -0.652167  0.276189  1.161493  ...  0.135988 -0.182828 -0.037648 -0.229441   \n",
       "1  0.693785 -0.254771 -0.094436  ...  0.192666  0.326074 -0.120927 -0.446195   \n",
       "2 -0.242937 -0.171510  2.468904  ... -0.508941 -0.841443  0.373076  1.107912   \n",
       "3  0.730886 -0.102934 -1.354044  ... -0.092148 -0.422369 -0.008842 -0.300789   \n",
       "4 -0.197253  0.166455  0.417873  ... -0.346103 -0.880483  0.136438 -0.435264   \n",
       "\n",
       "        v25       v26       v27       v28  amount  class  \n",
       "0 -0.588768  0.345469 -0.055816  0.026946  295.30      0  \n",
       "1  0.367994 -0.481879 -0.064670 -0.064917  101.50      0  \n",
       "2 -0.183633  0.001702 -0.059418 -0.054060    0.01      0  \n",
       "3  0.093130 -0.002726 -0.049081  0.011048   91.01      0  \n",
       "4  0.138783 -0.270529 -0.027408  0.005097   10.25      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping all the NANs \n",
    "dataset = dataset.dropna()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class column represents the transaction being fraudulent or not. \n",
    "The data set is highly imbalanced as is the case with most transaction based datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frauds:  172\n",
      "Number of non-frauds:  99828\n",
      "Percentage of fradulent data: 0.172\n"
     ]
    }
   ],
   "source": [
    "#Calculating the number of cases in both categories\n",
    "nonfrauds, frauds = dataset.groupby('class').size()\n",
    "print('Number of frauds: ', frauds)\n",
    "print('Number of non-frauds: ', nonfrauds)\n",
    "print('Percentage of fradulent data:', 100.*frauds/(frauds + nonfrauds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the feature columns without class column\n",
    "feature_columns = dataset.columns[:-1]\n",
    "# selecting the label column\n",
    "label_column = dataset.columns[-1]\n",
    "\n",
    "#extracting the values in the feature columns\n",
    "features = dataset[feature_columns].values.astype('float32')\n",
    "\n",
    "#extracting the values in the labels column\n",
    "labels = (dataset[label_column].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the sklearn module \n",
    "# importing the train test split to divide the data into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the datasets and uploading the created test and train datasets onto S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries \n",
    "import io\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.datasets import dump_svmlight_file   \n",
    "\n",
    "#Using the BytesIO because the data stored in S3 is an object\n",
    "# creating a buffer for Bytes IO\n",
    "buf = io.BytesIO()\n",
    "\n",
    "# dumping the files as object to the buffer\n",
    "sklearn.datasets.dump_svmlight_file(X_train, y_train, buf)\n",
    "buf.seek(0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training data location: s3://sagemaker-ap-south-1-080451317723/sagemaker-featurestore/train/base/fraud-dataset\n",
      "Training artifacts will be uploaded to: s3://sagemaker-ap-south-1-080451317723/sagemaker-featurestore/output\n"
     ]
    }
   ],
   "source": [
    "# initialising the directory in the S3 to store the data\n",
    "key = 'fraud-dataset'\n",
    "subdir = 'base'\n",
    "boto3.resource('s3', region_name=region).Bucket(default_s3_bucket_name).Object(os.path.join(prefix, 'train', subdir, key)).upload_fileobj(buf)\n",
    "\n",
    "# directory for storing the training data\n",
    "s3_train_data = 's3://{}/{}/train/{}/{}'.format(default_s3_bucket_name, prefix, subdir, key)\n",
    "print('Uploaded training data location: {}'.format(s3_train_data))\n",
    "\n",
    "# directory for storing the output artifacts\n",
    "output_location = 's3://{}/{}/output'.format(default_s3_bucket_name, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "Importing the XGBoost containers URI from sagemaker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the xgboost image URI\n",
    "import sagemaker\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an estimator for training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching the IAM role\n",
    "sagemaker_iam_role = sagemaker.get_execution_role()\n",
    "\n",
    "# creating a sagemaker session\n",
    "session = sagemaker.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an estimator with all the parameters (xgb container,\n",
    "#                                                role,\n",
    "#                                                instance count,\n",
    "#                                                instance type,\n",
    "#                                                output path,\n",
    "#                                                the sage maker session)\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=sagemaker_iam_role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path=output_location,\n",
    "                                    sagemaker_session=session)\n",
    "# setting up the hyper para meters for the xgboost \n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eval_metric='auc',\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:51:37 Starting - Starting the training job...\n",
      "2021-12-14 14:51:39 Starting - Launching requested ML instancesProfilerReport-1639493497: InProgress\n",
      "...\n",
      "2021-12-14 14:52:34 Starting - Preparing the instances for training............\n",
      "2021-12-14 14:54:30 Downloading - Downloading input data\n",
      "2021-12-14 14:54:30 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-12-14:14:54:44:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-12-14:14:54:44:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2021-12-14:14:54:44:INFO] File size need to be processed in the node: 55.3mb. Available memory size in the node: 8370.02mb\u001b[0m\n",
      "\u001b[34m[14:54:44] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:54:45] 90000x30 matrix with 2699427 entries loaded from /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[14:54:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.8967\u001b[0m\n",
      "\u001b[34m[14:54:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.902965\u001b[0m\n",
      "\u001b[34m[14:54:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.921795\u001b[0m\n",
      "\u001b[34m[14:54:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.921802\u001b[0m\n",
      "\u001b[34m[14:54:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.921801\u001b[0m\n",
      "\u001b[34m[14:54:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.921804\u001b[0m\n",
      "\u001b[34m[14:54:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.921809\u001b[0m\n",
      "\u001b[34m[14:54:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.921815\u001b[0m\n",
      "\u001b[34m[14:54:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.921736\u001b[0m\n",
      "\u001b[34m[14:54:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.921737\u001b[0m\n",
      "\u001b[34m[14:54:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.921736\u001b[0m\n",
      "\u001b[34m[14:54:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.921714\u001b[0m\n",
      "\u001b[34m[14:54:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.924749\u001b[0m\n",
      "\u001b[34m[14:54:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.92773\u001b[0m\n",
      "\u001b[34m[14:54:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.927689\u001b[0m\n",
      "\u001b[34m[14:54:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.927694\u001b[0m\n",
      "\u001b[34m[14:54:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.927629\u001b[0m\n",
      "\u001b[34m[14:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.92763\u001b[0m\n",
      "\u001b[34m[14:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.930634\u001b[0m\n",
      "\u001b[34m[14:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 8 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.930632\u001b[0m\n",
      "\u001b[34m[14:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.933186\u001b[0m\n",
      "\u001b[34m[14:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.93295\u001b[0m\n",
      "\u001b[34m[14:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.932791\u001b[0m\n",
      "\u001b[34m[14:54:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.951934\u001b[0m\n",
      "\u001b[34m[14:54:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.971193\u001b[0m\n",
      "\u001b[34m[14:54:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.971229\u001b[0m\n",
      "\u001b[34m[14:54:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.970409\u001b[0m\n",
      "\u001b[34m[14:54:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.977616\u001b[0m\n",
      "\u001b[34m[14:54:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.979688\u001b[0m\n",
      "\u001b[34m[14:54:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.979187\u001b[0m\n",
      "\u001b[34m[14:54:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.981225\u001b[0m\n",
      "\u001b[34m[14:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.980849\u001b[0m\n",
      "\u001b[34m[14:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.981319\u001b[0m\n",
      "\u001b[34m[14:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.985046\u001b[0m\n",
      "\u001b[34m[14:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.990811\u001b[0m\n",
      "\u001b[34m[14:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.990639\u001b[0m\n",
      "\u001b[34m[14:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.994668\u001b[0m\n",
      "\u001b[34m[14:54:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.994488\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.995645\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.995456\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.995441\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.994955\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.995884\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.996081\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.996487\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.996877\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.996803\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.997283\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.997448\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.99729\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.997511\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.997708\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.997758\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.998059\u001b[0m\n",
      "\u001b[34m[14:54:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.998101\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.998118\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.998202\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.998384\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.998425\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.998558\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.998569\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.998734\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[62]#011train-auc:0.998663\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[63]#011train-auc:0.998629\u001b[0m\n",
      "\u001b[34m[14:54:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[64]#011train-auc:0.99878\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[65]#011train-auc:0.998763\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[66]#011train-auc:0.998763\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[67]#011train-auc:0.998828\u001b[0m\n",
      "\n",
      "2021-12-14 14:55:07 Uploading - Uploading generated training model\n",
      "2021-12-14 14:55:07 Completed - Training job completed\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[68]#011train-auc:0.998764\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[69]#011train-auc:0.998863\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-auc:0.998863\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-auc:0.998863\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-auc:0.998863\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[73]#011train-auc:0.998829\u001b[0m\n",
      "\u001b[34m[14:54:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[74]#011train-auc:0.99888\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-auc:0.99888\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-auc:0.99888\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-auc:0.99888\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-auc:0.99888\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-auc:0.99888\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-auc:0.99888\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[81]#011train-auc:0.998868\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[82]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[84]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-auc:0.999008\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[91]#011train-auc:0.999021\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-auc:0.999021\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-auc:0.999021\u001b[0m\n",
      "\u001b[34m[14:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-auc:0.999021\u001b[0m\n",
      "\u001b[34m[14:54:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[95]#011train-auc:0.999051\u001b[0m\n",
      "\u001b[34m[14:54:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-auc:0.999051\u001b[0m\n",
      "\u001b[34m[14:54:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[97]#011train-auc:0.999182\u001b[0m\n",
      "\u001b[34m[14:54:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-auc:0.999182\u001b[0m\n",
      "\u001b[34m[14:54:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[99]#011train-auc:0.999276\u001b[0m\n",
      "Training seconds: 58\n",
      "Billable seconds: 58\n"
     ]
    }
   ],
   "source": [
    "# fitting the training data over our xgb estimator\n",
    "xgb.fit({'train': s3_train_data}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploying XGBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import CSVDeserializer,CSVSerializer\n",
    "\n",
    "# deploying the model created after training on endpoint\n",
    "\n",
    "predictor = xgb.deploy(initial_instance_count=1,\n",
    "                       model_name=\"{}-xgb\".format(\"fraud-detection\"),\n",
    "                       endpoint_name=\"{}-xgb\".format(\"fraud-detection\"),\n",
    "                       instance_type=\"ml.c5.xlarge\",\n",
    "                       serializer=CSVSerializer(),\n",
    "                       deserializer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# created small batches for prediction since the dataset is too large.\n",
    "def predict(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, current_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds = predict(predictor, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 1.0\n",
      "Cohen's Kappa = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Using cohen kappa score and balanced accuracy score  \n",
    "# because they take into account the frequency of occurences in imbalaced datasets.\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "\n",
    "# Putting in threshold for testing\n",
    "y_preds = np.where(raw_preds > 0.5, 1, 0)\n",
    "print(\"Balanced accuracy = {}\".format(balanced_accuracy_score(y_test, y_preds)))\n",
    "print(\"Cohen's Kappa = {}\".format(cohen_kappa_score(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# plotting the confusion matrix to understand the model's performance per class.\n",
    "def plot_confusion_matrix(y_true, y_predicted):\n",
    "\n",
    "    cm  = confusion_matrix(y_true, y_predicted)\n",
    "    # Obtaining the per-class normalized value for each sample point\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # coloring each cell as per their heat value\n",
    "    ax = sns.heatmap(cm_norm, annot=cm, fmt=\"d\")\n",
    "    ax.set(xticklabels=[\"non-fraud\", \"fraud\"], yticklabels=[\"non-fraud\", \"fraud\"])\n",
    "    ax.set_ylim([0,2])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-fraud       1.00      1.00      1.00      9988\n",
      "       fraud       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# creating a classification report\n",
    "print(classification_report(\n",
    "    y_test, y_preds, target_names=['non-fraud', 'fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performed very good on the dataset we provided. Since the data is highly imbalanced , trying few other techniques for better model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting imbalanced-learn==0.6.0\n",
      "  Using cached imbalanced_learn-0.6.0-py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn==0.6.0) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn==0.6.0) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn==0.6.0) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn==0.6.0) (1.4.1)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: scikit-learn==0.22.1 in /opt/conda/lib/python3.7/site-packages (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.22.1) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.22.1) (1.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn==0.6.0\n",
    "!pip install scikit-learn==0.22.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Smote ( synthetic minority over sampling )\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# initialising the smote module with random state of 42\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "#creating new dataset with smote applied\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 89840), (1.0, 89840)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# this will count the number of data point in each cateogry\n",
    "print(sorted(Counter(y_smote).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have equal number of cases for both the classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the smote dataset just created and upload it to S3 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training data location: s3://sagemaker-ap-south-1-080451317723/sagemaker-featurestore/train/smote/fraud-dataset-smote\n",
      "Training artifacts will be uploaded to: s3://sagemaker-ap-south-1-080451317723/sagemaker-featurestore/smote-output\n"
     ]
    }
   ],
   "source": [
    "smote_buf = io.BytesIO()\n",
    "\n",
    "# Dumping the smote data into a buffer\n",
    "sklearn.datasets.dump_svmlight_file(X_smote, y_smote, smote_buf)\n",
    "smote_buf.seek(0);\n",
    "\n",
    "# Uploading from buffer to s3\n",
    "key = 'fraud-dataset-smote'\n",
    "subdir = 'smote'\n",
    "boto3.resource('s3', region_name=region).Bucket(default_s3_bucket_name).Object(os.path.join(prefix, 'train', subdir, key)).upload_fileobj(smote_buf)\n",
    "\n",
    "s3_smote_train_data = 's3://{}/{}/train/{}/{}'.format(default_s3_bucket_name, prefix, subdir, key)\n",
    "print('Uploaded training data location: {}'.format(s3_smote_train_data))\n",
    "\n",
    "smote_output_location = 's3://{}/{}/smote-output'.format(default_s3_bucket_name, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(smote_output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating smote estimator with all the parameters.\n",
    "smote_xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=sagemaker_iam_role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path=output_location,\n",
    "                                    sagemaker_session=session)\n",
    "#setting up the hyper parameters\n",
    "smote_xgb.set_hyperparameters(max_depth=5,\n",
    "                        eval_metric='auc',\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:57:16 Starting - Starting the training job...\n",
      "2021-12-14 14:57:42 Starting - Launching requested ML instancesProfilerReport-1639493836: InProgress\n",
      "...\n",
      "2021-12-14 14:58:12 Starting - Preparing the instances for training.........\n",
      "2021-12-14 14:59:43 Downloading - Downloading input data...\n",
      "2021-12-14 15:00:18 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-12-14:15:00:19:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-12-14:15:00:19:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2021-12-14:15:00:19:INFO] File size need to be processed in the node: 110.3mb. Available memory size in the node: 8360.18mb\u001b[0m\n",
      "\u001b[34m[15:00:19] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:00:19] 179680x30 matrix with 5389380 entries loaded from /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[15:00:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.988866\u001b[0m\n",
      "\u001b[34m[15:00:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.995713\u001b[0m\n",
      "\u001b[34m[15:00:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.997317\u001b[0m\n",
      "\u001b[34m[15:00:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.99829\u001b[0m\n",
      "\u001b[34m[15:00:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.998738\u001b[0m\n",
      "\u001b[34m[15:00:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.999144\u001b[0m\n",
      "\u001b[34m[15:00:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.999576\u001b[0m\n",
      "\u001b[34m[15:00:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.999639\u001b[0m\n",
      "\u001b[34m[15:00:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.999677\u001b[0m\n",
      "\u001b[34m[15:00:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.99969\u001b[0m\n",
      "\u001b[34m[15:00:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.999706\u001b[0m\n",
      "\u001b[34m[15:00:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.999731\u001b[0m\n",
      "\u001b[34m[15:00:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.99976\u001b[0m\n",
      "\u001b[34m[15:00:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.999805\u001b[0m\n",
      "\u001b[34m[15:00:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.999817\u001b[0m\n",
      "\u001b[34m[15:00:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.999828\u001b[0m\n",
      "\u001b[34m[15:00:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.999845\u001b[0m\n",
      "\u001b[34m[15:00:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.999854\u001b[0m\n",
      "\u001b[34m[15:00:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.999859\u001b[0m\n",
      "\u001b[34m[15:00:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.999868\u001b[0m\n",
      "\u001b[34m[15:00:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.999867\u001b[0m\n",
      "\u001b[34m[15:00:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.999868\u001b[0m\n",
      "\u001b[34m[15:00:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.999874\u001b[0m\n",
      "\u001b[34m[15:00:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.999881\u001b[0m\n",
      "\u001b[34m[15:00:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.999879\u001b[0m\n",
      "\u001b[34m[15:00:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.999912\u001b[0m\n",
      "\u001b[34m[15:00:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.999913\u001b[0m\n",
      "\u001b[34m[15:00:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.999917\u001b[0m\n",
      "\u001b[34m[15:00:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.999922\u001b[0m\n",
      "\u001b[34m[15:00:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.999927\u001b[0m\n",
      "\u001b[34m[15:00:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.999927\u001b[0m\n",
      "\u001b[34m[15:00:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.999933\u001b[0m\n",
      "\u001b[34m[15:00:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.999931\u001b[0m\n",
      "\u001b[34m[15:00:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.999953\u001b[0m\n",
      "\u001b[34m[15:00:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.999953\u001b[0m\n",
      "\u001b[34m[15:00:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.999959\u001b[0m\n",
      "\u001b[34m[15:00:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.999959\u001b[0m\n",
      "\u001b[34m[15:00:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.999963\u001b[0m\n",
      "\u001b[34m[15:00:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.999963\u001b[0m\n",
      "\u001b[34m[15:00:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.999964\u001b[0m\n",
      "\u001b[34m[15:00:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.999965\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.999965\u001b[0m\n",
      "\u001b[34m[15:00:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15:00:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.999966\u001b[0m\n",
      "\u001b[34m[15:00:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.999973\u001b[0m\n",
      "\u001b[34m[15:00:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.999973\u001b[0m\n",
      "\u001b[34m[15:00:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.999975\u001b[0m\n",
      "\u001b[34m[15:00:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.999978\u001b[0m\n",
      "\u001b[34m[15:00:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.99998\u001b[0m\n",
      "\u001b[34m[15:00:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.999983\u001b[0m\n",
      "\u001b[34m[15:00:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.999986\u001b[0m\n",
      "\u001b[34m[15:00:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.999986\u001b[0m\n",
      "\u001b[34m[15:00:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.999987\u001b[0m\n",
      "\u001b[34m[15:00:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.999988\u001b[0m\n",
      "\u001b[34m[15:00:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.999988\u001b[0m\n",
      "\u001b[34m[15:00:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.99999\u001b[0m\n",
      "\u001b[34m[15:00:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.99999\u001b[0m\n",
      "\u001b[34m[15:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.999991\u001b[0m\n",
      "\u001b[34m[15:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.999991\u001b[0m\n",
      "\u001b[34m[15:00:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.999993\u001b[0m\n",
      "\u001b[34m[15:00:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.999993\u001b[0m\n",
      "\u001b[34m[15:00:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.999995\u001b[0m\n",
      "\u001b[34m[15:00:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.999995\u001b[0m\n",
      "\u001b[34m[15:00:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-auc:0.999996\u001b[0m\n",
      "\u001b[34m[15:00:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-auc:0.999996\u001b[0m\n",
      "\u001b[34m[15:00:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-auc:0.999996\u001b[0m\n",
      "\u001b[34m[15:00:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-auc:0.999997\u001b[0m\n",
      "\u001b[34m[15:00:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-auc:0.999997\u001b[0m\n",
      "\u001b[34m[15:00:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[67]#011train-auc:0.999998\u001b[0m\n",
      "\u001b[34m[15:00:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-auc:0.999998\u001b[0m\n",
      "\u001b[34m[15:00:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[69]#011train-auc:0.999998\u001b[0m\n",
      "\u001b[34m[15:00:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[70]#011train-auc:0.999998\u001b[0m\n",
      "\u001b[34m[15:00:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-auc:0.999998\u001b[0m\n",
      "\u001b[34m[15:00:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[72]#011train-auc:0.999998\u001b[0m\n",
      "\u001b[34m[15:00:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[73]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[75]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[76]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[78]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 10 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[79]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[81]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[83]#011train-auc:0.999999\u001b[0m\n",
      "\u001b[34m[15:00:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 10 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[84]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 10 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[85]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[86]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[87]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[89]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[90]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 20 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[91]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 16 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[92]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 16 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[93]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[95]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[96]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-auc:1\u001b[0m\n",
      "\u001b[34m[15:00:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[99]#011train-auc:1\u001b[0m\n",
      "\n",
      "2021-12-14 15:01:04 Uploading - Uploading generated training model\n",
      "2021-12-14 15:01:04 Completed - Training job completed\n",
      "Training seconds: 83\n",
      "Billable seconds: 83\n"
     ]
    }
   ],
   "source": [
    "# fitting the data \n",
    "smote_xgb.fit({'train': s3_smote_train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "# prediting the outputs \n",
    "from sagemaker.predictor import CSVDeserializer,CSVSerializer\n",
    "\n",
    "predictor = smote_xgb.deploy(initial_instance_count=1,\n",
    "                       model_name=\"{}-xgb\".format(\"fraud-detection-smote\"),\n",
    "                       endpoint_name=\"{}-xgb\".format(\"fraud-detection-smote\"),\n",
    "                       instance_type=\"ml.c5.xlarge\",\n",
    "                       serializer=CSVSerializer(),\n",
    "                       deserializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the predictions\n",
    "smote_raw_preds = predict(predictor, X_test)\n",
    "# setting up a threshold\n",
    "smote_preds = np.where(smote_raw_preds > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.9999499399279135\n",
      "Cohen's Kappa = 0.9599500176219923\n"
     ]
    }
   ],
   "source": [
    "print(\"Balanced accuracy = {}\".format(balanced_accuracy_score(y_test, smote_preds)))\n",
    "print(\"Cohen's Kappa = {}\".format(cohen_kappa_score(y_test, smote_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, smote_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-fraud       1.00      1.00      1.00      9988\n",
      "       fraud       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       0.96      1.00      0.98     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating the classification report for the smote dataset\n",
    "print(classification_report(\n",
    "    y_test, smote_preds, target_names=['non-fraud', 'fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1\n",
      "Balanced accuracy = 0.999\n",
      "Cohen's Kappa = 0.666\n",
      "\n",
      "Threshold: 0.2\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 0.774\n",
      "\n",
      "Threshold: 0.3\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 0.827\n",
      "\n",
      "Threshold: 0.4\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 0.857\n",
      "\n",
      "Threshold: 0.5\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 0.960\n",
      "\n",
      "Threshold: 0.6\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 0.960\n",
      "\n",
      "Threshold: 0.7\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 1.000\n",
      "\n",
      "Threshold: 0.8\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 1.000\n",
      "\n",
      "Threshold: 0.9\n",
      "Balanced accuracy = 1.000\n",
      "Cohen's Kappa = 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying for various thresholds for best results\n",
    "for thres in np.linspace(0.1, 0.9, num=9):\n",
    "    smote_thres_preds = np.where(smote_raw_preds > thres, 1, 0)\n",
    "    print(\"Threshold: {:.1f}\".format(thres))\n",
    "    print(\"Balanced accuracy = {:.3f}\".format(balanced_accuracy_score(y_test, smote_thres_preds)))\n",
    "    print(\"Cohen's Kappa = {:.3f}\\n\".format(cohen_kappa_score(y_test, smote_thres_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The cohen's kappa increases with the threshold values without loss in balances accuracy. \n",
    "\n",
    "### Inference:\n",
    "\n",
    "We can keep low threshold if \" not missing fraudulent cases\" is our priority \n",
    "\n",
    "or \n",
    "\n",
    "we can keep high threshold to minimise the number of false positives."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
